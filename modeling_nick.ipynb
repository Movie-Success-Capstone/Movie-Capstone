{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "03b137da-b44a-46e9-951f-811a5261b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wrangle as w \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0efd84e-5061-4ef2-b40b-9b803522472c",
   "metadata": {},
   "source": [
    "First I need to modify the dataframe and make a separate version of it for modeling; split, scale, fit_transform, make dataframes have the same columns (actor dummies may complicate this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d81dc246-7953-46ab-9192-b756c9bf890f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached CSV\n"
     ]
    }
   ],
   "source": [
    "df = w.wrangle_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e0d7ba-6acb-4b05-b8a3-3b110ae64718",
   "metadata": {},
   "source": [
    "I originally wanted to one-hot encode for every instance of cast_actor_1, 2, and 3, but the resultant shape is so large as to become unworkable (at least in a reasonable time span."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8ff6857e-7aba-46e5-b3e3-75bd91b6669f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UniversalPictures                     398\n",
       "ParamountPictures                     386\n",
       "TwentiethCenturyFoxFilmCorporation    291\n",
       "ColumbiaPictures                      232\n",
       "NewLineCinema                         184\n",
       "WarnerBros.                           162\n",
       "WaltDisneyPictures                    145\n",
       "Metro-Goldwyn-Mayer(MGM)              107\n",
       "ColumbiaPicturesCorporation           104\n",
       "UnitedArtists                         101\n",
       "Name: production_company, dtype: int64"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.production_company.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4a093d36-3bf7-4ed5-979d-f2fc8f4585b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 101\n",
    "df.loc[df['production_company'].value_counts()\\\n",
    "       [df['production_company']].values < threshold, 'production_company'] = \"other_company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "3c810950-2735-4656-b840-721938338ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_company                         4783\n",
       "UniversalPictures                      398\n",
       "ParamountPictures                      386\n",
       "TwentiethCenturyFoxFilmCorporation     291\n",
       "ColumbiaPictures                       232\n",
       "NewLineCinema                          184\n",
       "WarnerBros.                            162\n",
       "WaltDisneyPictures                     145\n",
       "Metro-Goldwyn-Mayer(MGM)               107\n",
       "ColumbiaPicturesCorporation            104\n",
       "UnitedArtists                          101\n",
       "Name: production_company, dtype: int64"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.production_company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9ac3521a-3d0d-4cca-922b-bc6d88778d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nicolas Cage          41\n",
       "Robert De Niro        37\n",
       "Bruce Willis          36\n",
       "Sylvester Stallone    35\n",
       "Johnny Depp           34\n",
       "Denzel Washington     33\n",
       "Tom Hanks             33\n",
       "Clint Eastwood        32\n",
       "Tom Cruise            30\n",
       "Robin Williams        26\n",
       "Name: cast_actor_1, dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cast_actor_1.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d50b80f1-63e4-4e90-afa1-d540b4331f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 26\n",
    "df.loc[df['cast_actor_1'].value_counts()\\\n",
    "       [df['cast_actor_1']].values < threshold, 'cast_actor_1'] = \"other_actor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0f86feb1-7774-4e52-a1f2-6f0877f36854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_actor              6452\n",
       "Nicolas Cage               41\n",
       "Robert De Niro             37\n",
       "Bruce Willis               36\n",
       "Sylvester Stallone         35\n",
       "Johnny Depp                34\n",
       "Tom Hanks                  33\n",
       "Denzel Washington          33\n",
       "Clint Eastwood             32\n",
       "Tom Cruise                 30\n",
       "Arnold Schwarzenegger      26\n",
       "Kevin Costner              26\n",
       "Robin Williams             26\n",
       "John Travolta              26\n",
       "Adam Sandler               26\n",
       "Name: cast_actor_1, dtype: int64"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cast_actor_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "3fe2c82a-1b0e-4c0f-973c-70ebd7bf707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_group = ['cast_actor_1', 'production_company']\n",
    "dummy_df = pd.get_dummies(df.loc[:,dummy_group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "42ae8105-6155-4479-947f-739c836581fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep =  ['budget','runtime', 'vote_average','vote_count', 'success', \n",
    "         'release_year', 'is_genre_adventure', 'is_genre_horror', \n",
    "         'is_genre_drama', 'is_genre_scifi', 'is_genre_romance',\n",
    "         'is_genre_thriller', 'is_genre_crime', 'is_genre_comedy',\n",
    "         'is_genre_animation', 'is_genre_action', 'is_genre_mystery',\n",
    "         'is_genre_fantasy', 'is_genre_documentary', 'total_n_cast']\n",
    "# success will be the only one of these that is not used as a predictor, given that it is our target\n",
    "# I'm not sure if revenue would be appropriate to include. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "4320ac53-e20c-4a1a-96d8-50418e2b828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = df.loc[:,keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "60242d69-602d-4ae4-9464-2665b7d04365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dummy dataframe to original \n",
    "modeling_df = pd.concat([modeling_df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "8a5e56e4-ec1c-4e34-9d85-1edff083c5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6893, 46)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a5844cc1-a7a3-4a3e-8e18-df255c5c8789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['budget', 'runtime', 'vote_average', 'vote_count', 'success',\n",
       "       'release_year', 'is_genre_adventure', 'is_genre_horror',\n",
       "       'is_genre_drama', 'is_genre_scifi', 'is_genre_romance',\n",
       "       'is_genre_thriller', 'is_genre_crime', 'is_genre_comedy',\n",
       "       'is_genre_animation', 'is_genre_action', 'is_genre_mystery',\n",
       "       'is_genre_fantasy', 'is_genre_documentary', 'total_n_cast',\n",
       "       'cast_actor_1_Adam Sandler', 'cast_actor_1_Arnold Schwarzenegger',\n",
       "       'cast_actor_1_Bruce Willis', 'cast_actor_1_Clint Eastwood',\n",
       "       'cast_actor_1_Denzel Washington', 'cast_actor_1_John Travolta',\n",
       "       'cast_actor_1_Johnny Depp', 'cast_actor_1_Kevin Costner',\n",
       "       'cast_actor_1_Nicolas Cage', 'cast_actor_1_Robert De Niro',\n",
       "       'cast_actor_1_Robin Williams', 'cast_actor_1_Sylvester Stallone',\n",
       "       'cast_actor_1_Tom Cruise', 'cast_actor_1_Tom Hanks',\n",
       "       'cast_actor_1_other_actor', 'production_company_ColumbiaPictures',\n",
       "       'production_company_ColumbiaPicturesCorporation',\n",
       "       'production_company_Metro-Goldwyn-Mayer(MGM)',\n",
       "       'production_company_NewLineCinema',\n",
       "       'production_company_ParamountPictures',\n",
       "       'production_company_TwentiethCenturyFoxFilmCorporation',\n",
       "       'production_company_UnitedArtists',\n",
       "       'production_company_UniversalPictures',\n",
       "       'production_company_WaltDisneyPictures',\n",
       "       'production_company_WarnerBros.', 'production_company_other_company'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ea772-5914-4fce-814a-6ceee638f58b",
   "metadata": {},
   "source": [
    "The data types are as they should be, as far as I know. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4bc78dc0-89dc-4dfe-a665-a247a577fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.train_validate_test_split(modeling_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7c6ef8e7-3d3b-4222-8981-71c231fd88e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3859, 46)\n",
      "validate: (1655, 46)\n",
      "test: (1379, 46)\n"
     ]
    }
   ],
   "source": [
    "print('train:', train.shape)\n",
    "print('validate:', validate.shape)\n",
    "print('test:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b7324-c43b-4092-a84c-9a1c035cf1e1",
   "metadata": {},
   "source": [
    "***\n",
    "Time to scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d6338db2-5d76-4cec-ba2c-54184085d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['success'])\n",
    "y_train = train['success']\n",
    "\n",
    "X_validate = validate.drop(columns=['success'])\n",
    "y_validate = validate['success']\n",
    "\n",
    "X_test = test.drop(columns=['success'])\n",
    "y_test = test['success']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "29a1965b-6576-4b86-b971-ac77b95d7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I need to scale. \n",
    "needs_scaling = ['budget','runtime', 'vote_average',\n",
    "                 'vote_count','release_year', 'total_n_cast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0d06e053-929a-4239-8a0b-a9a9bddbf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = MinMaxScaler()\n",
    "## Note that we only call .fit with the training data,\n",
    "## but we use .transform to apply the scaling to all the data splits.\n",
    "#scaler.fit(X_train[needs_scaling])\n",
    "#\n",
    "#X_train_scaled = pd.DataFrame(scaler.transform(X_train[needs_scaling]))\n",
    "#X_validate_scaled = pd.DataFrame(scaler.transform(X_validate[needs_scaling]))\n",
    "#X_test_scaled = pd.DataFrame(scaler.transform(X_test[needs_scaling]))\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_validate_scaled = scaler.transform(X_validate)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train_scaled, index=X_train.index, columns = X_train.columns)\n",
    "X_validate = pd.DataFrame(X_validate_scaled, index=X_validate.index, columns = X_validate.columns)\n",
    "X_test = pd.DataFrame(X_test_scaled, index=X_test.index, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "f4604888-f67e-4c94-b015-ede0e66a0ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2358\n",
       "1    1501\n",
       "Name: success, dtype: int64"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ebb4fbc2-7b58-4fc6-8f2b-551d2d881f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['baseline_prediction'] = 0\n",
    "X_validate['baseline_prediction'] = 0\n",
    "X_test['baseline_prediction'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "b5bf39e7-571f-4ad7-8521-0ec7860d2f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3859, 46)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "8a49a72f-7920-4610-9bd8-0b0db265dece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3859,)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c0dbabac-a369-4019-b2f5-cefddecb0b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I want it for later\n",
    "#train_scaled = X_train.merge(ytdf, how='left', on=X_train.index)\n",
    "#validate_scaled = X_validate.merge(yvdf, how='left', left_index = True, right_index = True)\n",
    "#train_scaled = X_train.merge(ytedf, how='left', left_index = True, right_index = True)\n",
    "train_scaled = X_train.copy()\n",
    "train_scaled['success'] = y_train\n",
    "\n",
    "validate_scaled = X_validate.copy()\n",
    "validate_scaled['success'] = y_validate\n",
    "\n",
    "test_scaled = X_test.copy()\n",
    "test_scaled['success'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "aeb78009-a713-40ee-9533-c11ddbf9202e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3859, 47)\n",
      "validate: (1655, 47)\n",
      "test: (1379, 47)\n"
     ]
    }
   ],
   "source": [
    "print('train:', train_scaled.shape)\n",
    "print('validate:', validate_scaled.shape)\n",
    "print('test:', test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "93401e31-3437-4e61-ae6a-98b7971380de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print grid search results\n",
    "def print_cv_results(gs, title):\n",
    "    print('\\n -----------------------------------------')\n",
    "    print(title)\n",
    "\n",
    "    print(f'Best Score = {gs.best_score_:.4f}')\n",
    "    print(f'Best Hyper-parameters = {gs.best_params_}')\n",
    "    print()\n",
    "\n",
    "    print('Test Scores:')\n",
    "    test_means = gs.cv_results_['mean_test_score']\n",
    "    test_stds = gs.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(test_means, test_stds, gs.cv_results_['params']):\n",
    "        print(f'{mean:.4f} (+/-{std:.3f}) for {params}')\n",
    "    print()\n",
    "\n",
    "    print('Training Scores:')\n",
    "    train_means = gs.cv_results_['mean_train_score']\n",
    "    train_stds = gs.cv_results_['std_train_score']\n",
    "    for mean, std, params in zip(train_means, train_stds, gs.cv_results_['params']):\n",
    "        print(f'{mean:.4f} (+/-{std:.3f}) for {params}')\n",
    "    print('\\n -----------------------------------------')\n",
    "    \n",
    "        # save grid search results to file\n",
    "def save_cv_results(gs, title, fileName):\n",
    "    with open(fileName, 'a') as f:\n",
    "        \n",
    "        print(title, file=f)\n",
    "\n",
    "        print(f'Best Score = {gs.best_score_:.4f}', file=f)\n",
    "        print(f'Best Hyper-parameters = {gs.best_params_}', file=f)\n",
    "        print('', file=f)\n",
    "\n",
    "        print('Test Scores:', file=f)\n",
    "        test_means = gs.cv_results_['mean_test_score']\n",
    "        test_stds = gs.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(test_means, test_stds, gs.cv_results_['params']):\n",
    "            print(f'{mean:.4f} (+/-{std:.3f}) for {params}', file=f)\n",
    "        print('', file=f)\n",
    "\n",
    "        print('Training Scores:', file=f)\n",
    "        train_means = gs.cv_results_['mean_train_score']\n",
    "        train_stds = gs.cv_results_['std_train_score']\n",
    "        for mean, std, params in zip(train_means, train_stds, gs.cv_results_['params']):\n",
    "            print(f'{mean:.4f} (+/-{std:.3f}) for {params}', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "868db255-2a2f-40ce-a90e-a627ce46f039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -----------------------------------------\n",
      "Logistic Regression Accuracy\n",
      "Best Score = 0.7746\n",
      "Best Hyper-parameters = {'C': 100, 'solver': 'saga'}\n",
      "\n",
      "Test Scores:\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'newton-cg'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'lbfgs'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'sag'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'saga'}\n",
      "0.6393 (+/-0.002) for {'C': 0.01, 'solver': 'newton-cg'}\n",
      "0.6393 (+/-0.002) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.6393 (+/-0.002) for {'C': 0.01, 'solver': 'sag'}\n",
      "0.6393 (+/-0.002) for {'C': 0.01, 'solver': 'saga'}\n",
      "0.6968 (+/-0.005) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.6968 (+/-0.005) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.6968 (+/-0.005) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.6968 (+/-0.005) for {'C': 0.1, 'solver': 'saga'}\n",
      "0.7398 (+/-0.008) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.7398 (+/-0.008) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.7398 (+/-0.008) for {'C': 1, 'solver': 'sag'}\n",
      "0.7398 (+/-0.008) for {'C': 1, 'solver': 'saga'}\n",
      "0.7681 (+/-0.000) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.7681 (+/-0.000) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.7681 (+/-0.000) for {'C': 10, 'solver': 'sag'}\n",
      "0.7683 (+/-0.000) for {'C': 10, 'solver': 'saga'}\n",
      "0.7740 (+/-0.001) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.7740 (+/-0.001) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.7743 (+/-0.002) for {'C': 100, 'solver': 'sag'}\n",
      "0.7746 (+/-0.002) for {'C': 100, 'solver': 'saga'}\n",
      "0.7743 (+/-0.002) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.7743 (+/-0.002) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.7743 (+/-0.002) for {'C': 1000, 'solver': 'sag'}\n",
      "0.7743 (+/-0.002) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      "Training Scores:\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'newton-cg'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'lbfgs'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'sag'}\n",
      "0.6110 (+/-0.000) for {'C': 0.001, 'solver': 'saga'}\n",
      "0.6462 (+/-0.006) for {'C': 0.01, 'solver': 'newton-cg'}\n",
      "0.6462 (+/-0.006) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.6462 (+/-0.006) for {'C': 0.01, 'solver': 'sag'}\n",
      "0.6462 (+/-0.006) for {'C': 0.01, 'solver': 'saga'}\n",
      "0.7099 (+/-0.002) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.7099 (+/-0.002) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.7099 (+/-0.002) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.7099 (+/-0.002) for {'C': 0.1, 'solver': 'saga'}\n",
      "0.7546 (+/-0.003) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.7546 (+/-0.003) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.7546 (+/-0.003) for {'C': 1, 'solver': 'sag'}\n",
      "0.7545 (+/-0.003) for {'C': 1, 'solver': 'saga'}\n",
      "0.7799 (+/-0.001) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.7799 (+/-0.001) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.7799 (+/-0.001) for {'C': 10, 'solver': 'sag'}\n",
      "0.7800 (+/-0.001) for {'C': 10, 'solver': 'saga'}\n",
      "0.7827 (+/-0.001) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.7828 (+/-0.000) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.7830 (+/-0.001) for {'C': 100, 'solver': 'sag'}\n",
      "0.7830 (+/-0.001) for {'C': 100, 'solver': 'saga'}\n",
      "0.7827 (+/-0.001) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.7828 (+/-0.001) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.7827 (+/-0.001) for {'C': 1000, 'solver': 'sag'}\n",
      "0.7827 (+/-0.001) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      " -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logReg = LogisticRegression(max_iter=1000)\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = {'C': c_list,\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "gs = GridSearchCV(estimator=logReg,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  cv=3,\n",
    "                  return_train_score=True)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print_cv_results(gs, 'Logistic Regression Accuracy')\n",
    "save_cv_results(gs, 'Logistic Regression Accuracy', 'Mastersheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ff32d86f-6cdb-4898-86a3-38af6a0d0763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -----------------------------------------\n",
      "Logistic Regression Precision\n",
      "Best Score = 0.7836\n",
      "Best Hyper-parameters = {'C': 100, 'solver': 'saga'}\n",
      "\n",
      "Test Scores:\n",
      "0.7478 (+/-0.013) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.7478 (+/-0.013) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.7470 (+/-0.012) for {'C': 1, 'solver': 'sag'}\n",
      "0.7478 (+/-0.013) for {'C': 1, 'solver': 'saga'}\n",
      "0.7818 (+/-0.008) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.7818 (+/-0.008) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.7818 (+/-0.008) for {'C': 10, 'solver': 'sag'}\n",
      "0.7826 (+/-0.009) for {'C': 10, 'solver': 'saga'}\n",
      "0.7827 (+/-0.006) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.7827 (+/-0.006) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.7829 (+/-0.006) for {'C': 100, 'solver': 'sag'}\n",
      "0.7836 (+/-0.005) for {'C': 100, 'solver': 'saga'}\n",
      "0.7814 (+/-0.007) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.7814 (+/-0.007) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.7814 (+/-0.007) for {'C': 1000, 'solver': 'sag'}\n",
      "0.7814 (+/-0.007) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      "Training Scores:\n",
      "0.7738 (+/-0.007) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.7738 (+/-0.007) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.7740 (+/-0.007) for {'C': 1, 'solver': 'sag'}\n",
      "0.7736 (+/-0.007) for {'C': 1, 'solver': 'saga'}\n",
      "0.7994 (+/-0.005) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.7994 (+/-0.005) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.7994 (+/-0.005) for {'C': 10, 'solver': 'sag'}\n",
      "0.7997 (+/-0.005) for {'C': 10, 'solver': 'saga'}\n",
      "0.7966 (+/-0.007) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.7966 (+/-0.007) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.7973 (+/-0.007) for {'C': 100, 'solver': 'sag'}\n",
      "0.7973 (+/-0.007) for {'C': 100, 'solver': 'saga'}\n",
      "0.7955 (+/-0.006) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.7956 (+/-0.006) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.7955 (+/-0.006) for {'C': 1000, 'solver': 'sag'}\n",
      "0.7955 (+/-0.006) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      " -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logReg = LogisticRegression(max_iter=1000)\n",
    "c_list = [ 1, 10, 100, 1000]\n",
    "param_grid = {'C': c_list,\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "gs = GridSearchCV(estimator=logReg,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring = 'precision',\n",
    "                  cv=3,\n",
    "                  return_train_score=True)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print_cv_results(gs, 'Logistic Regression Precision')\n",
    "save_cv_results(gs, 'Logistic Regression Precision', 'Mastersheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3e2964f6-b1a8-48c1-8c90-e8b73efcdc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -----------------------------------------\n",
      "Logistic Regression Recall\n",
      "Best Score = 0.5829\n",
      "Best Hyper-parameters = {'C': 1000, 'solver': 'newton-cg'}\n",
      "\n",
      "Test Scores:\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'newton-cg'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'lbfgs'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'sag'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'saga'}\n",
      "0.1799 (+/-0.008) for {'C': 0.01, 'solver': 'newton-cg'}\n",
      "0.1799 (+/-0.008) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.1799 (+/-0.008) for {'C': 0.01, 'solver': 'sag'}\n",
      "0.1799 (+/-0.008) for {'C': 0.01, 'solver': 'saga'}\n",
      "0.4111 (+/-0.005) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.4111 (+/-0.005) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.4111 (+/-0.005) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.4111 (+/-0.005) for {'C': 0.1, 'solver': 'saga'}\n",
      "0.4997 (+/-0.020) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.4997 (+/-0.020) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.4997 (+/-0.020) for {'C': 1, 'solver': 'sag'}\n",
      "0.4997 (+/-0.020) for {'C': 1, 'solver': 'saga'}\n",
      "0.5603 (+/-0.012) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.5603 (+/-0.012) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.5603 (+/-0.012) for {'C': 10, 'solver': 'sag'}\n",
      "0.5603 (+/-0.012) for {'C': 10, 'solver': 'saga'}\n",
      "0.5803 (+/-0.012) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.5803 (+/-0.012) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.5809 (+/-0.013) for {'C': 100, 'solver': 'sag'}\n",
      "0.5809 (+/-0.013) for {'C': 100, 'solver': 'saga'}\n",
      "0.5829 (+/-0.013) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.5829 (+/-0.013) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.5829 (+/-0.013) for {'C': 1000, 'solver': 'sag'}\n",
      "0.5829 (+/-0.013) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      "Training Scores:\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'newton-cg'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'lbfgs'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'sag'}\n",
      "0.0000 (+/-0.000) for {'C': 0.001, 'solver': 'saga'}\n",
      "0.1902 (+/-0.007) for {'C': 0.01, 'solver': 'newton-cg'}\n",
      "0.1902 (+/-0.007) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.1902 (+/-0.007) for {'C': 0.01, 'solver': 'sag'}\n",
      "0.1902 (+/-0.007) for {'C': 0.01, 'solver': 'saga'}\n",
      "0.4250 (+/-0.010) for {'C': 0.1, 'solver': 'newton-cg'}\n",
      "0.4250 (+/-0.010) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.4250 (+/-0.010) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.4250 (+/-0.010) for {'C': 0.1, 'solver': 'saga'}\n",
      "0.5217 (+/-0.002) for {'C': 1, 'solver': 'newton-cg'}\n",
      "0.5217 (+/-0.002) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.5217 (+/-0.002) for {'C': 1, 'solver': 'sag'}\n",
      "0.5213 (+/-0.001) for {'C': 1, 'solver': 'saga'}\n",
      "0.5796 (+/-0.008) for {'C': 10, 'solver': 'newton-cg'}\n",
      "0.5796 (+/-0.008) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.5796 (+/-0.008) for {'C': 10, 'solver': 'sag'}\n",
      "0.5796 (+/-0.008) for {'C': 10, 'solver': 'saga'}\n",
      "0.5929 (+/-0.007) for {'C': 100, 'solver': 'newton-cg'}\n",
      "0.5933 (+/-0.007) for {'C': 100, 'solver': 'lbfgs'}\n",
      "0.5929 (+/-0.007) for {'C': 100, 'solver': 'sag'}\n",
      "0.5929 (+/-0.007) for {'C': 100, 'solver': 'saga'}\n",
      "0.5943 (+/-0.008) for {'C': 1000, 'solver': 'newton-cg'}\n",
      "0.5946 (+/-0.008) for {'C': 1000, 'solver': 'lbfgs'}\n",
      "0.5943 (+/-0.008) for {'C': 1000, 'solver': 'sag'}\n",
      "0.5943 (+/-0.008) for {'C': 1000, 'solver': 'saga'}\n",
      "\n",
      " \n",
      " -----------------------------------------\n",
      "\n",
      " -----------------------------------------\n",
      "\n",
      " \n",
      " -----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "logReg = LogisticRegression(max_iter=1000)\n",
    "c_list = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "param_grid = {'C': c_list,\n",
    "              'solver': ['newton-cg', 'lbfgs', 'sag', 'saga']}\n",
    "\n",
    "gs = GridSearchCV(estimator=logReg,\n",
    "                  param_grid=param_grid,\n",
    "                  scoring='recall',\n",
    "                  cv=3,\n",
    "                  return_train_score=True)\n",
    "gs = gs.fit(X_train, y_train)\n",
    "print_cv_results(gs, 'Logistic Regression Recall')\n",
    "save_cv_results(gs, 'Logistic Regression Precision', 'Mastersheet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8241cf3-30ec-4081-8d47-c4f13c5b42db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
